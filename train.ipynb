{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEurtVduiUBx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.ndimage import label\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "from model import BrainTumorSegmentationModel\n",
        "from torch.utils.data import random_split\n",
        "from dataset import BraTSDataset\n",
        "import csv\n",
        "from torch.utils.tensorboard import SummaryWriter  # Option TensorBoard\n",
        "\n",
        "# Initialisation CSV\n",
        "with open('training_metrics.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\n",
        "        'epoch',\n",
        "        'train_loss',\n",
        "        'val_dice_et', 'val_dice_tc', 'val_dice_wt',\n",
        "        'val_hd_et', 'val_hd_tc', 'val_hd_wt'\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "#le modèle\n",
        "model = BrainTumorSegmentationModel(in_channels=1, num_classes=3)\n",
        "\n",
        "# Optimiseur\n",
        "optimizer = Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCELoss()\n",
        "\n",
        "    def forward(self, preds, targets, smooth=1e-5):\n",
        "        bce_loss = self.bce(preds, targets)\n",
        "\n",
        "        dice_loss = 0.0\n",
        "        for i in range(preds.shape[1]):\n",
        "            pred = preds[:, i]\n",
        "            target = targets[:, i]\n",
        "            intersection = (pred * target).sum()\n",
        "            dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "            dice_loss += 1 - dice\n",
        "\n",
        "        dice_loss /= preds.shape[1]\n",
        "        return bce_loss + dice_loss\n",
        "\n",
        "# Fonction de perte\n",
        "criterion = BCEDiceLoss()\n",
        "\n",
        "train_set=BraTSDataset(\"BraTS2021_Augmented\")\n",
        "val_set = BraTSDataset(\"BraTS2021_Val\")\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "# Dice Score\n",
        "def dice_score(preds, targets, smooth=1e-5):\n",
        "    scores = []\n",
        "    for i in range(preds.shape[1]):\n",
        "        pred = preds[:, i]\n",
        "        target = targets[:, i]\n",
        "        intersection = (pred * target).sum()\n",
        "        dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "        scores.append(dice.item())\n",
        "    return scores\n",
        "\n",
        "# Fonction Hausdorff95\n",
        "def hausdorff95(pred, target):\n",
        "    pred = pred.astype(bool)\n",
        "    target = target.astype(bool)\n",
        "\n",
        "    if pred.sum() == 0 or target.sum() == 0:\n",
        "        return np.nan\n",
        "\n",
        "    pred_pts = np.argwhere(pred)\n",
        "    target_pts = np.argwhere(target)\n",
        "\n",
        "    d1 = directed_hausdorff(pred_pts, target_pts)[0]\n",
        "    d2 = directed_hausdorff(target_pts, pred_pts)[0]\n",
        "\n",
        "    return np.percentile([d1, d2], 95)\n",
        "\n",
        "# Supprimer petits ET < 200 voxels\n",
        "def remove_small_et(pred, min_size=200):\n",
        "    et = pred[0]  # ET est le premier canal\n",
        "    labeled, num = label(et)\n",
        "    for i in range(1, num + 1):\n",
        "        if (labeled == i).sum() < min_size:\n",
        "            et[labeled == i] = 0\n",
        "    pred[0] = et\n",
        "    return pred\n",
        "\n",
        "# Boucle d'entraînement + validation\n",
        "n_epochs = 100\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: (1 - epoch / n_epochs) ** 0.9)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for flair, t1, t1ce, t2, mask in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
        "        flair, t1, t1ce, t2, mask = flair.to(device), t1.to(device), t1ce.to(device), t2.to(device), mask.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            et = (mask == 4).float()\n",
        "            tc = ((mask == 1) | (mask == 4)).float()\n",
        "            wt = ((mask == 1) | (mask == 2) | (mask == 4)).float()\n",
        "            target = torch.cat([et, tc, wt], dim=1)\n",
        "\n",
        "        output = model(flair, t1, t1ce, t2)\n",
        "        loss = criterion(output, target)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\" Epoch {epoch+1} terminé - Loss moyenne : {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    dice_totals = [0.0, 0.0, 0.0]\n",
        "    hausdorff_totals = [0.0, 0.0, 0.0]\n",
        "    valid_counts = [0, 0, 0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for flair, t1, t1ce, t2, mask in val_loader:\n",
        "            flair, t1, t1ce, t2, mask = flair.to(device), t1.to(device), t1ce.to(device), t2.to(device), mask.to(device)\n",
        "\n",
        "            et = (mask == 4).float()\n",
        "            tc = ((mask == 1) | (mask == 4)).float()\n",
        "            wt = ((mask == 1) | (mask == 2) | (mask == 4)).float()\n",
        "            target = torch.cat([et, tc, wt], dim=1)\n",
        "\n",
        "            output = model(flair, t1, t1ce, t2)\n",
        "            preds = (output > 0.5).float().cpu().numpy()\n",
        "            target_np = target.cpu().numpy()\n",
        "\n",
        "            # Supprimer petits ET\n",
        "            preds[0] = remove_small_et(preds[0])\n",
        "\n",
        "            # Dice\n",
        "            dices = dice_score(torch.tensor(preds), torch.tensor(target_np))\n",
        "            dice_totals = [dice_totals[i] + dices[i] for i in range(3)]\n",
        "\n",
        "            # Hausdorff95\n",
        "            for i in range(3):\n",
        "                hd = hausdorff95(preds[0, i], target_np[0, i])\n",
        "                if not np.isnan(hd):\n",
        "                    hausdorff_totals[i] += hd\n",
        "                    valid_counts[i] += 1\n",
        "\n",
        "    n = len(val_loader)\n",
        "    dice_avgs = [d / n for d in dice_totals]\n",
        "    hausdorff_avgs = [hausdorff_totals[i] / valid_counts[i] if valid_counts[i] > 0 else float('nan') for i in range(3)]\n",
        "\n",
        "    print(f\" Dice Validation - ET: {dice_avgs[0]:.4f} | TC: {dice_avgs[1]:.4f} | WT: {dice_avgs[2]:.4f}\")\n",
        "    print(f\"c      - ET: {hausdorff_avgs[0]:.2f} | TC: {hausdorff_avgs[1]:.2f} | WT: {hausdorff_avgs[2]:.2f}\")\n",
        "    scheduler.step()\n",
        "\n",
        "    # Sauvegarde des métriques dans CSV\n",
        "    with open('training_metrics.csv', 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            epoch + 1,\n",
        "            epoch_loss / len(train_loader),\n",
        "            dice_avgs[0], dice_avgs[1], dice_avgs[2],\n",
        "            hausdorff_avgs[0], hausdorff_avgs[1], hausdorff_avgs[2]\n",
        "        ])\n",
        "\n",
        "\n",
        "\n",
        "    # sauvegarde du modèle après la dernière époque\n",
        "    torch.save(model.state_dict(), \"brain_tumor_model.pth\")\n",
        "    print(\"Modèle entraîné et sauvegardé avec succès.\")"
      ]
    }
  ]
}