{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEurtVduiUBx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Conv3d, ConvTranspose3d, MaxPool3d, BatchNorm3d, ReLU, Softmax\n",
        "\n",
        "\"\"\"Blocs de base : **RésidualBlock3D**\"\"\"\n",
        "\n",
        "class ResidualBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock3D, self).__init__()\n",
        "        self.conv1 = Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = BatchNorm3d(out_channels)\n",
        "        self.relu = ReLU()\n",
        "        self.conv2 = Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = BatchNorm3d(out_channels)\n",
        "\n",
        "        self.skip = Conv3d(in_channels, out_channels, kernel_size=1, padding=0) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.skip(x)\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += identity\n",
        "        return self.relu(out)\n",
        "\n",
        "\"\"\"Bloc d'encodage : **EncoderBlock**\"\"\"\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, features):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.block = ResidualBlock3D(in_channels, features)\n",
        "        self.pool = MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        skip = x\n",
        "        x = self.pool(x)\n",
        "        return x, skip\n",
        "\n",
        "\"\"\"**Encodeur simple pour une modalité : SingleEncoder**\"\"\"\n",
        "\n",
        "class SingleEncoder(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SingleEncoder, self).__init__()\n",
        "        self.enc1 = EncoderBlock(in_channels, 16)\n",
        "        self.enc2 = EncoderBlock(16, 32)\n",
        "        self.enc3 = EncoderBlock(32, 64)\n",
        "        self.enc4 = EncoderBlock(64, 128)\n",
        "        self.enc5 = ResidualBlock3D(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, skip1 = self.enc1(x)\n",
        "        x, skip2 = self.enc2(x)\n",
        "        x, skip3 = self.enc3(x)\n",
        "        x, skip4 = self.enc4(x)\n",
        "        x = self.enc5(x)\n",
        "        return x, [skip4, skip3, skip2, skip1]\n",
        "\n",
        "\"\"\"**Encodeur multi-modalité : MultiModalEncoder**\"\"\"\n",
        "\n",
        "class MultiModalEncoder(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(MultiModalEncoder, self).__init__()\n",
        "        self.encoder_flair = SingleEncoder(in_channels)\n",
        "        self.encoder_t1 = SingleEncoder(in_channels)\n",
        "        self.encoder_t1ce = SingleEncoder(in_channels)\n",
        "        self.encoder_t2 = SingleEncoder(in_channels)\n",
        "\n",
        "    def forward(self, flair, t1, t1ce, t2):\n",
        "        flair_out, flair_skips = self.encoder_flair(flair)\n",
        "        t1_out, t1_skips = self.encoder_t1(t1)\n",
        "        t1ce_out, t1ce_skips = self.encoder_t1ce(t1ce)\n",
        "        t2_out, t2_skips = self.encoder_t2(t2)\n",
        "        return (flair_out, t1_out, t1ce_out, t2_out), [flair_skips, t1_skips, t1ce_skips, t2_skips]\n",
        "\n",
        "\"\"\"**Transformées en ondelettes : DWT_3D et IDWT_3D**\"\"\"\n",
        "\n",
        "def simple_dwt3d(x):\n",
        "    b, c, d, h, w = x.shape\n",
        "    d, h, w = d // 2, h // 2, w // 2\n",
        "\n",
        "    return [\n",
        "        x[:, :, 0::2, 0::2, 0::2],  # LLL\n",
        "        x[:, :, 1::2, 0::2, 0::2],  # HLL\n",
        "        x[:, :, 0::2, 1::2, 0::2],  # LHL\n",
        "        x[:, :, 1::2, 1::2, 0::2],  # HHL\n",
        "        x[:, :, 0::2, 0::2, 1::2],  # LLH\n",
        "        x[:, :, 1::2, 0::2, 1::2],  # HLH\n",
        "        x[:, :, 0::2, 1::2, 1::2],  # LHH\n",
        "        x[:, :, 1::2, 1::2, 1::2],  # HHH\n",
        "    ]\n",
        "\n",
        "def simple_idwt3d(subbands):\n",
        "    lll, hll, lhl, hhl, llh, hlh, lhh, hhh = subbands\n",
        "    b, c, d, h, w = lll.shape\n",
        "    out = torch.zeros((b, c, d*2, h*2, w*2), device=lll.device)\n",
        "\n",
        "    out[:, :, 0::2, 0::2, 0::2] = lll\n",
        "    out[:, :, 1::2, 0::2, 0::2] = hll\n",
        "    out[:, :, 0::2, 1::2, 0::2] = lhl\n",
        "    out[:, :, 1::2, 1::2, 0::2] = hhl\n",
        "    out[:, :, 0::2, 0::2, 1::2] = llh\n",
        "    out[:, :, 1::2, 0::2, 1::2] = hlh\n",
        "    out[:, :, 0::2, 1::2, 1::2] = lhh\n",
        "    out[:, :, 1::2, 1::2, 1::2] = hhh\n",
        "\n",
        "    return out\n",
        "\n",
        "def fuse_subbands(subband_lists):\n",
        "    fused = []\n",
        "    lll = torch.stack([bands[0] for bands in subband_lists]).mean(dim=0)\n",
        "    fused.append(lll)\n",
        "    for i in range(1, 8):\n",
        "        high = sum(bands[i] for bands in subband_lists)\n",
        "        fused.append(high)\n",
        "    return fused\n",
        "\n",
        "\"\"\"**Module de fusion par ondelettes : WaveletFusionModule**\"\"\"\n",
        "\n",
        "class WaveletFusionModule(nn.Module):\n",
        "    def forward(self, flair, t1, t1ce, t2):\n",
        "        flair_bands = simple_dwt3d(flair)\n",
        "        t1_bands = simple_dwt3d(t1)\n",
        "        t1ce_bands = simple_dwt3d(t1ce)\n",
        "        t2_bands = simple_dwt3d(t2)\n",
        "\n",
        "        fused_bands = fuse_subbands([flair_bands, t1_bands, t1ce_bands, t2_bands])\n",
        "        fused_feature = simple_idwt3d(fused_bands)\n",
        "\n",
        "        # Injection dans chaque modalité\n",
        "        flair_out = flair + fused_feature\n",
        "        t1_out = t1 + fused_feature\n",
        "        t1ce_out = t1ce + fused_feature\n",
        "        t2_out = t2 + fused_feature\n",
        "\n",
        "        # Concaténation des 4 modalités après injection\n",
        "        return torch.cat([flair_out, t1_out, t1ce_out, t2_out], dim=1)\n",
        "\n",
        "\"\"\"**Module d’attention contextuelle : GlobalContextAwareModule**\"\"\"\n",
        "\n",
        "class GlobalContextAwareModule(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GlobalContextAwareModule, self).__init__()\n",
        "        self.conv1 = Conv3d(in_channels, in_channels, kernel_size=1)\n",
        "        self.softmax = Softmax(dim=1)\n",
        "        self.transform = nn.Sequential(\n",
        "            Conv3d(in_channels, in_channels, kernel_size=1),\n",
        "            BatchNorm3d(in_channels),\n",
        "            ReLU(),\n",
        "            Conv3d(in_channels, in_channels, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        context = self.conv1(x)\n",
        "        attention = self.softmax(context)\n",
        "        l_context = x * attention\n",
        "        l_trans = self.transform(l_context)\n",
        "        return x + l_trans\n",
        "\n",
        "\"\"\"**Bloc de décodage : DecoderBlock3D**\"\"\"\n",
        "\n",
        "class DecoderBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, skip_channels, out_channels):\n",
        "        super(DecoderBlock3D, self).__init__()\n",
        "        self.upconv = ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.conv1 = Conv3d(out_channels + skip_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = BatchNorm3d(out_channels)\n",
        "        self.relu = ReLU()\n",
        "        self.conv2 = Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upconv(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        return self.conv2(x)\n",
        "\n",
        "\"\"\"**Modèle complet : BrainTumorSegmentationModel**\"\"\"\n",
        "\n",
        "class BrainTumorSegmentationModel(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(BrainTumorSegmentationModel, self).__init__()\n",
        "        self.encoder = MultiModalEncoder(in_channels)\n",
        "\n",
        "        # Wavelet Fusion Modules\n",
        "        self.wfm_final = WaveletFusionModule()\n",
        "        self.wfm4 = WaveletFusionModule()\n",
        "        self.wfm3 = WaveletFusionModule()\n",
        "        self.wfm2 = WaveletFusionModule()\n",
        "        self.wfm1 = WaveletFusionModule()\n",
        "        self.gcam = GlobalContextAwareModule(1024)\n",
        "\n",
        "        # Decoder blocks\n",
        "        self.dec4 = DecoderBlock3D(1024, 4 * 128, 128)  # 4x128 = 512\n",
        "        self.dec3 = DecoderBlock3D(128, 4 * 64, 64)     # 4x64 = 256\n",
        "        self.dec2 = DecoderBlock3D(64, 4 * 32, 32)      # 4x32 = 128\n",
        "        self.dec1 = DecoderBlock3D(32, 4 * 16, 16)      # 4x16 = 64\n",
        "\n",
        "        self.final = Conv3d(16, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, flair, t1, t1ce, t2):\n",
        "        # Encoders\n",
        "        (f, t1_, t1ce_, t2_), skips = self.encoder(flair, t1, t1ce, t2)\n",
        "        print(f\"Sortie encoder : {f.shape}, {t1_.shape}, {t1ce_.shape}, {t2_.shape}\")\n",
        "        # Final fusion des sorties d'encodeurs\n",
        "        fused_concat  = self.wfm_final(f, t1_, t1ce_, t2_)\n",
        "        print(f\"Sortie après fusion : {fused_concat.shape}\")\n",
        "\n",
        "        gcam_out = self.gcam(fused_concat)\n",
        "        print(f\"Sortie après GCAM : {gcam_out.shape}\")\n",
        "\n",
        "        # DAffichage des tailles des skip connections\n",
        "        for i, skip_list in enumerate(skips):\n",
        "            for j, skip in enumerate(skip_list):\n",
        "                print(f\"Shape skip {i+1}-{j+1}: {skip.shape}\")\n",
        "\n",
        "        # Fusion des skip connections à chaque niveau\n",
        "        s4 = self.wfm4(*[x[0] for x in skips])\n",
        "        s3 = self.wfm3(*[x[1] for x in skips])\n",
        "        s2 = self.wfm2(*[x[2] for x in skips])\n",
        "        s1 = self.wfm1(*[x[3] for x in skips])\n",
        "\n",
        "        # Decoder avec skip connections fusionnées\n",
        "        x = self.dec4(gcam_out, s4)\n",
        "        print(f\"Sortie après dec4 : {x.shape}\")\n",
        "        x = self.dec3(x, s3)\n",
        "        print(f\"Sortie après dec3 : {x.shape}\")\n",
        "        x = self.dec2(x, s2)\n",
        "        print(f\"Sortie après dec2 : {x.shape}\")\n",
        "        x = self.dec1(x, s1)\n",
        "        print(f\"Sortie après dec1 : {x.shape}\")\n",
        "\n",
        "        #\n",
        "        return torch.sigmoid(self.final(x))\n",
        "\n",
        "model = BrainTumorSegmentationModel(in_channels=1, num_classes=3)"
      ]
    }
  ]
}